{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headline Generation (NLP)\n",
    "***\n",
    "![Newspaper](Images/HeadlineImage.jpg)\n",
    "***\n",
    "In this tutorial we are going to use a recurrent neural network to look at headlines from newspapers, to then be able to generate new headlines based on the seed (first few words) that we give it. The data we have given you contains only American headlines, so it will be biased. We suggest trying your own data if you find something similar!\n",
    "***\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "set_random_seed(2)\n",
    "seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Load the Data\n",
    "Here we have data define the exact file we want to load in as we only want the data that is associated with articles and not the comments.\n",
    "\n",
    "To Do:\n",
    "- Load all **article** data\n",
    "- Take a look at the headlines that we have loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Clean the Data\n",
    "We need to clean the text of the data because it appears to be in unicode which is why we get apostrophe's appearing like \"\\xe2\\x80\\x99\". We will define a function where we can pass all of our text through and which returns the text without any punctuation and capitol letters. \n",
    "\n",
    "To Do:\n",
    "- Write a function which checks for punctuation, removes it and changes all letters to lower case\n",
    "- Pass your data through the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Tokenise\n",
    "With the Twitter Classification we tokenised our words, we will do the same here and create a bag of words. A bag of words is something which counts the amount of occurences of given word and labels it with a unique identifier. \n",
    "\n",
    "To Do:\n",
    "- Define a function to get a sequence of tokens\n",
    "- Define a function to generate padded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Create the Model and Train\n",
    "We're going to create a model using a Long Short Term Memory (LSTM) layer. Traditional neural networks usually throw away what they've learned previously and start over again. Recurrent Nueral Networks (RNN) are different, what they learn persists through each layer. A typical RNN can struggle to identify and learn the long term dependecies of the data. This is where a LSTM comes in as it is capable of learning long term dependencies. \n",
    "\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "To Do:\n",
    "- Create a model with the following layers:\n",
    "            Embedding\n",
    "            LSTM\n",
    "            Dense\n",
    "- Compile the model\n",
    "- Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Generate your Headlines\n",
    "To generate the headlines we are going to create a function which takes in the beggining of our headline (the topic), how long you want the headline to be, the model we created and how long we want our sequences to be. \n",
    "\n",
    "To Do:\n",
    "- Create a generate_text function\n",
    "- Generate different headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
